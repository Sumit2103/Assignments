{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.preprocessing import StandardScaler \n",
    "from sklearn import datasets\n",
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "boston = datasets.load_boston() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD',\n",
       "       'TAX', 'PTRATIO', 'B', 'LSTAT'], dtype='<U7')"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boston.feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "#boston"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = pd.DataFrame(boston.data, columns=boston.feature_names) \n",
    "# y = boston.target \n",
    "# y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#boston.DESCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6.3200e-03, 1.8000e+01, 2.3100e+00, ..., 1.5300e+01, 3.9690e+02,\n",
       "        4.9800e+00],\n",
       "       [2.7310e-02, 0.0000e+00, 7.0700e+00, ..., 1.7800e+01, 3.9690e+02,\n",
       "        9.1400e+00],\n",
       "       [2.7290e-02, 0.0000e+00, 7.0700e+00, ..., 1.7800e+01, 3.9283e+02,\n",
       "        4.0300e+00],\n",
       "       ...,\n",
       "       [6.0760e-02, 0.0000e+00, 1.1930e+01, ..., 2.1000e+01, 3.9690e+02,\n",
       "        5.6400e+00],\n",
       "       [1.0959e-01, 0.0000e+00, 1.1930e+01, ..., 2.1000e+01, 3.9345e+02,\n",
       "        6.4800e+00],\n",
       "       [4.7410e-02, 0.0000e+00, 1.1930e+01, ..., 2.1000e+01, 3.9690e+02,\n",
       "        7.8800e+00]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#boston.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "bos= pd.DataFrame(boston.data,columns=boston.feature_names)\n",
    "bos['price']=boston.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 506 entries, 0 to 505\n",
      "Data columns (total 14 columns):\n",
      " #   Column   Non-Null Count  Dtype  \n",
      "---  ------   --------------  -----  \n",
      " 0   CRIM     506 non-null    float64\n",
      " 1   ZN       506 non-null    float64\n",
      " 2   INDUS    506 non-null    float64\n",
      " 3   CHAS     506 non-null    float64\n",
      " 4   NOX      506 non-null    float64\n",
      " 5   RM       506 non-null    float64\n",
      " 6   AGE      506 non-null    float64\n",
      " 7   DIS      506 non-null    float64\n",
      " 8   RAD      506 non-null    float64\n",
      " 9   TAX      506 non-null    float64\n",
      " 10  PTRATIO  506 non-null    float64\n",
      " 11  B        506 non-null    float64\n",
      " 12  LSTAT    506 non-null    float64\n",
      " 13  price    506 non-null    float64\n",
      "dtypes: float64(14)\n",
      "memory usage: 55.5 KB\n"
     ]
    }
   ],
   "source": [
    "bos.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "      <td>34.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD    TAX  \\\n",
       "0  0.00632  18.0   2.31   0.0  0.538  6.575  65.2  4.0900  1.0  296.0   \n",
       "1  0.02731   0.0   7.07   0.0  0.469  6.421  78.9  4.9671  2.0  242.0   \n",
       "2  0.02729   0.0   7.07   0.0  0.469  7.185  61.1  4.9671  2.0  242.0   \n",
       "3  0.03237   0.0   2.18   0.0  0.458  6.998  45.8  6.0622  3.0  222.0   \n",
       "4  0.06905   0.0   2.18   0.0  0.458  7.147  54.2  6.0622  3.0  222.0   \n",
       "\n",
       "   PTRATIO       B  LSTAT  price  \n",
       "0     15.3  396.90   4.98   24.0  \n",
       "1     17.8  396.90   9.14   21.6  \n",
       "2     17.8  392.83   4.03   34.7  \n",
       "3     18.7  394.63   2.94   33.4  \n",
       "4     18.7  396.90   5.33   36.2  "
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bos.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = bos.iloc[:,:-1]\n",
    "y = bos.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv=KFold(n_splits=10,shuffle=True,random_state=2103)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KFold(n_splits=10, random_state=2103, shuffle=True)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(array([  0,   1,   2,   3,   4,   5,   6,   7,   9,  10,  11,  12,  13,\n",
       "          14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  26,  27,  28,\n",
       "          29,  31,  32,  33,  34,  35,  36,  37,  38,  40,  41,  42,  43,\n",
       "          44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  56,  57,\n",
       "          58,  60,  61,  62,  63,  64,  66,  68,  69,  70,  71,  72,  73,\n",
       "          74,  75,  76,  77,  78,  79,  81,  84,  85,  86,  87,  88,  89,\n",
       "          90,  91,  92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 103,\n",
       "         104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116,\n",
       "         117, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 131,\n",
       "         132, 133, 134, 135, 136, 137, 138, 140, 141, 142, 143, 144, 145,\n",
       "         146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158,\n",
       "         159, 160, 162, 163, 165, 167, 168, 169, 170, 171, 172, 173, 174,\n",
       "         176, 177, 178, 179, 180, 181, 183, 184, 185, 187, 188, 189, 190,\n",
       "         192, 193, 194, 195, 196, 197, 198, 199, 201, 202, 203, 205, 206,\n",
       "         207, 208, 209, 210, 211, 212, 213, 214, 216, 217, 218, 219, 220,\n",
       "         221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233,\n",
       "         234, 235, 236, 237, 239, 240, 241, 242, 243, 244, 245, 246, 247,\n",
       "         248, 250, 251, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262,\n",
       "         263, 264, 265, 266, 267, 268, 269, 271, 272, 273, 274, 275, 276,\n",
       "         277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289,\n",
       "         290, 292, 293, 294, 296, 297, 298, 299, 300, 301, 304, 305, 306,\n",
       "         307, 308, 309, 310, 312, 313, 314, 315, 316, 317, 318, 319, 320,\n",
       "         321, 322, 323, 324, 325, 327, 328, 329, 330, 331, 332, 333, 334,\n",
       "         335, 336, 337, 338, 339, 340, 341, 344, 345, 346, 347, 348, 349,\n",
       "         350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362,\n",
       "         363, 364, 365, 366, 367, 369, 370, 371, 373, 374, 375, 376, 379,\n",
       "         380, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393,\n",
       "         394, 395, 397, 398, 399, 400, 401, 402, 403, 404, 406, 407, 408,\n",
       "         409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421,\n",
       "         422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434,\n",
       "         435, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448,\n",
       "         449, 450, 451, 452, 454, 455, 456, 458, 460, 461, 462, 463, 464,\n",
       "         465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477,\n",
       "         478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490,\n",
       "         491, 492, 493, 494, 495, 496, 498, 500, 501, 502, 503, 504, 505]),\n",
       "  array([  8,  24,  25,  30,  39,  55,  59,  65,  67,  80,  82,  83, 102,\n",
       "         118, 130, 139, 161, 164, 166, 175, 182, 186, 191, 200, 204, 215,\n",
       "         238, 249, 252, 270, 291, 295, 302, 303, 311, 326, 342, 343, 368,\n",
       "         372, 377, 378, 381, 396, 405, 436, 453, 457, 459, 497, 499])),\n",
       " (array([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,\n",
       "          13,  14,  15,  16,  17,  18,  20,  21,  22,  23,  24,  25,  26,\n",
       "          27,  28,  29,  30,  31,  32,  34,  35,  36,  37,  38,  39,  40,\n",
       "          41,  42,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,\n",
       "          55,  56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,\n",
       "          68,  69,  70,  71,  72,  73,  74,  76,  77,  78,  79,  80,  81,\n",
       "          82,  83,  84,  85,  86,  87,  89,  90,  91,  92,  93,  95,  96,\n",
       "          97,  98,  99, 100, 102, 103, 104, 105, 106, 107, 108, 109, 110,\n",
       "         111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123,\n",
       "         124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136,\n",
       "         137, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150,\n",
       "         151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163,\n",
       "         164, 165, 166, 167, 168, 170, 171, 172, 174, 175, 177, 178, 179,\n",
       "         180, 181, 182, 183, 184, 185, 186, 188, 189, 190, 191, 192, 193,\n",
       "         194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206,\n",
       "         207, 208, 209, 210, 212, 213, 214, 215, 216, 217, 218, 219, 220,\n",
       "         221, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 235,\n",
       "         236, 237, 238, 239, 240, 241, 242, 244, 245, 246, 247, 249, 250,\n",
       "         251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263,\n",
       "         264, 265, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277,\n",
       "         279, 280, 281, 282, 283, 284, 285, 286, 288, 289, 290, 291, 292,\n",
       "         293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305,\n",
       "         306, 308, 310, 311, 312, 313, 314, 315, 318, 319, 320, 321, 322,\n",
       "         323, 324, 326, 327, 329, 330, 332, 333, 334, 335, 336, 337, 338,\n",
       "         339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351,\n",
       "         354, 356, 357, 359, 360, 361, 362, 363, 364, 365, 366, 368, 369,\n",
       "         370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382,\n",
       "         383, 384, 385, 387, 389, 390, 391, 392, 394, 396, 397, 398, 399,\n",
       "         400, 401, 402, 404, 405, 406, 407, 408, 409, 411, 412, 415, 416,\n",
       "         417, 418, 419, 420, 421, 422, 423, 425, 426, 427, 428, 430, 432,\n",
       "         433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445,\n",
       "         446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 457, 458, 459,\n",
       "         460, 461, 463, 464, 466, 467, 468, 469, 470, 471, 472, 473, 474,\n",
       "         475, 476, 478, 479, 480, 481, 482, 483, 484, 485, 487, 488, 489,\n",
       "         492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 505]),\n",
       "  array([ 19,  33,  43,  75,  88,  94, 101, 138, 169, 173, 176, 187, 211,\n",
       "         222, 234, 243, 248, 266, 278, 287, 307, 309, 316, 317, 325, 328,\n",
       "         331, 352, 353, 355, 358, 367, 386, 388, 393, 395, 403, 410, 413,\n",
       "         414, 424, 429, 431, 456, 462, 465, 477, 486, 490, 491, 504])),\n",
       " (array([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  11,  12,  14,\n",
       "          15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
       "          28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  41,\n",
       "          42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,\n",
       "          55,  57,  58,  59,  60,  61,  62,  64,  65,  66,  67,  68,  69,\n",
       "          70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,\n",
       "          83,  85,  87,  88,  89,  90,  91,  93,  94,  95,  96,  97, 100,\n",
       "         101, 102, 103, 104, 105, 107, 108, 109, 110, 111, 113, 114, 115,\n",
       "         116, 117, 118, 119, 120, 121, 122, 123, 124, 126, 128, 129, 130,\n",
       "         131, 132, 133, 134, 135, 136, 137, 138, 139, 142, 143, 144, 145,\n",
       "         147, 148, 149, 151, 152, 153, 154, 156, 157, 158, 159, 160, 161,\n",
       "         162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174,\n",
       "         175, 176, 177, 178, 180, 181, 182, 184, 185, 186, 187, 190, 191,\n",
       "         192, 193, 194, 195, 196, 197, 198, 199, 200, 202, 203, 204, 205,\n",
       "         206, 207, 208, 209, 210, 211, 212, 213, 215, 216, 217, 218, 219,\n",
       "         220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 231, 232, 233,\n",
       "         234, 235, 236, 237, 238, 239, 240, 241, 243, 244, 245, 246, 247,\n",
       "         248, 249, 250, 252, 253, 254, 256, 257, 258, 259, 260, 261, 262,\n",
       "         263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275,\n",
       "         276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 289,\n",
       "         290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 301, 302, 303,\n",
       "         304, 305, 306, 307, 308, 309, 310, 311, 313, 314, 316, 317, 318,\n",
       "         319, 321, 322, 323, 325, 326, 327, 328, 329, 330, 331, 332, 333,\n",
       "         334, 335, 336, 337, 338, 339, 340, 342, 343, 344, 347, 348, 349,\n",
       "         350, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363,\n",
       "         364, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378,\n",
       "         379, 380, 381, 382, 383, 384, 385, 386, 388, 390, 391, 392, 393,\n",
       "         394, 395, 396, 397, 398, 399, 400, 403, 404, 405, 406, 407, 408,\n",
       "         409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421,\n",
       "         422, 423, 424, 425, 426, 428, 429, 430, 431, 432, 433, 434, 435,\n",
       "         436, 437, 438, 440, 441, 442, 443, 445, 446, 447, 448, 449, 451,\n",
       "         452, 453, 454, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465,\n",
       "         466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478,\n",
       "         479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491,\n",
       "         492, 493, 494, 495, 496, 497, 498, 499, 500, 502, 503, 504, 505]),\n",
       "  array([ 10,  13,  40,  56,  63,  84,  86,  92,  98,  99, 106, 112, 125,\n",
       "         127, 140, 141, 146, 150, 155, 179, 183, 188, 189, 201, 214, 230,\n",
       "         242, 251, 255, 288, 300, 312, 315, 320, 324, 341, 345, 346, 351,\n",
       "         365, 366, 387, 389, 401, 402, 427, 439, 444, 450, 455, 501])),\n",
       " (array([  0,   1,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,  14,\n",
       "          15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
       "          28,  29,  30,  32,  33,  35,  36,  38,  39,  40,  41,  42,  43,\n",
       "          44,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,  56,  57,\n",
       "          59,  61,  62,  63,  64,  65,  66,  67,  68,  69,  70,  71,  73,\n",
       "          74,  75,  76,  77,  78,  80,  81,  82,  83,  84,  85,  86,  87,\n",
       "          88,  89,  90,  91,  92,  93,  94,  95,  96,  97,  98,  99, 100,\n",
       "         101, 102, 103, 105, 106, 107, 109, 110, 111, 112, 113, 114, 115,\n",
       "         117, 118, 119, 120, 121, 122, 124, 125, 127, 128, 129, 130, 131,\n",
       "         132, 133, 134, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145,\n",
       "         146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158,\n",
       "         159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171,\n",
       "         172, 173, 175, 176, 177, 178, 179, 180, 181, 182, 183, 185, 186,\n",
       "         187, 188, 189, 190, 191, 192, 193, 194, 196, 197, 198, 199, 200,\n",
       "         201, 202, 203, 204, 205, 206, 209, 210, 211, 212, 213, 214, 215,\n",
       "         217, 219, 220, 221, 222, 223, 224, 226, 227, 228, 229, 230, 231,\n",
       "         233, 234, 235, 236, 237, 238, 239, 241, 242, 243, 245, 246, 248,\n",
       "         249, 250, 251, 252, 253, 255, 256, 258, 259, 260, 261, 262, 263,\n",
       "         264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 276, 277,\n",
       "         278, 280, 282, 283, 284, 286, 287, 288, 290, 291, 292, 293, 294,\n",
       "         295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307,\n",
       "         308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320,\n",
       "         321, 323, 324, 325, 326, 327, 328, 329, 330, 331, 334, 335, 336,\n",
       "         337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 348, 349, 350,\n",
       "         351, 352, 353, 354, 355, 356, 358, 359, 360, 361, 363, 364, 365,\n",
       "         366, 367, 368, 369, 370, 372, 373, 374, 375, 376, 377, 378, 379,\n",
       "         380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392,\n",
       "         393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405,\n",
       "         407, 408, 409, 410, 411, 413, 414, 415, 416, 417, 418, 419, 420,\n",
       "         421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433,\n",
       "         434, 435, 436, 437, 438, 439, 440, 442, 443, 444, 445, 448, 449,\n",
       "         450, 451, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 464,\n",
       "         465, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 479,\n",
       "         480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492,\n",
       "         493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505]),\n",
       "  array([  2,   3,  31,  34,  37,  45,  58,  60,  72,  79, 104, 108, 116,\n",
       "         123, 126, 135, 174, 184, 195, 207, 208, 216, 218, 225, 232, 240,\n",
       "         244, 247, 254, 257, 275, 279, 281, 285, 289, 322, 332, 333, 347,\n",
       "         357, 362, 371, 406, 412, 441, 446, 447, 452, 463, 466, 478])),\n",
       " (array([  1,   2,   3,   4,   5,   7,   8,   9,  10,  11,  12,  13,  14,\n",
       "          15,  16,  17,  18,  19,  20,  22,  23,  24,  25,  27,  28,  29,\n",
       "          30,  31,  32,  33,  34,  35,  37,  38,  39,  40,  41,  43,  44,\n",
       "          45,  47,  48,  49,  50,  51,  53,  54,  55,  56,  58,  59,  60,\n",
       "          61,  63,  64,  65,  66,  67,  68,  69,  70,  71,  72,  73,  75,\n",
       "          76,  77,  79,  80,  81,  82,  83,  84,  86,  87,  88,  89,  90,\n",
       "          92,  93,  94,  95,  96,  98,  99, 100, 101, 102, 103, 104, 105,\n",
       "         106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118,\n",
       "         119, 120, 121, 122, 123, 124, 125, 126, 127, 130, 131, 132, 133,\n",
       "         134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146,\n",
       "         147, 148, 149, 150, 151, 152, 154, 155, 156, 157, 158, 159, 160,\n",
       "         161, 162, 163, 164, 165, 166, 168, 169, 170, 171, 172, 173, 174,\n",
       "         175, 176, 177, 178, 179, 180, 182, 183, 184, 185, 186, 187, 188,\n",
       "         189, 191, 193, 194, 195, 196, 197, 198, 200, 201, 202, 203, 204,\n",
       "         205, 206, 207, 208, 209, 211, 212, 213, 214, 215, 216, 217, 218,\n",
       "         219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231,\n",
       "         232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244,\n",
       "         245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 257, 258,\n",
       "         260, 261, 262, 263, 264, 265, 266, 268, 269, 270, 272, 273, 274,\n",
       "         275, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288,\n",
       "         289, 290, 291, 292, 293, 295, 296, 298, 299, 300, 301, 302, 303,\n",
       "         304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316,\n",
       "         317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329,\n",
       "         330, 331, 332, 333, 334, 335, 337, 338, 340, 341, 342, 343, 345,\n",
       "         346, 347, 348, 350, 351, 352, 353, 354, 355, 356, 357, 358, 360,\n",
       "         361, 362, 364, 365, 366, 367, 368, 369, 370, 371, 372, 374, 375,\n",
       "         376, 377, 378, 379, 381, 382, 383, 384, 385, 386, 387, 388, 389,\n",
       "         390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402,\n",
       "         403, 404, 405, 406, 407, 408, 409, 410, 412, 413, 414, 416, 417,\n",
       "         418, 420, 422, 424, 425, 426, 427, 428, 429, 431, 432, 433, 434,\n",
       "         435, 436, 437, 438, 439, 440, 441, 442, 444, 445, 446, 447, 449,\n",
       "         450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462,\n",
       "         463, 465, 466, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477,\n",
       "         478, 480, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492,\n",
       "         493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505]),\n",
       "  array([  0,   6,  21,  26,  36,  42,  46,  52,  57,  62,  74,  78,  85,\n",
       "          91,  97, 128, 129, 153, 167, 181, 190, 192, 199, 210, 256, 259,\n",
       "         267, 271, 276, 294, 297, 336, 339, 344, 349, 359, 363, 373, 380,\n",
       "         411, 415, 419, 421, 423, 430, 443, 448, 464, 467, 479, 481])),\n",
       " (array([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  13,\n",
       "          14,  15,  16,  17,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
       "          28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  39,  40,  41,\n",
       "          42,  43,  44,  45,  46,  47,  48,  49,  52,  53,  55,  56,  57,\n",
       "          58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  70,  71,  72,\n",
       "          73,  74,  75,  76,  78,  79,  80,  82,  83,  84,  85,  86,  87,\n",
       "          88,  90,  91,  92,  93,  94,  95,  96,  97,  98,  99, 100, 101,\n",
       "         102, 104, 105, 106, 107, 108, 109, 110, 111, 112, 115, 116, 117,\n",
       "         118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130,\n",
       "         132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 144, 145,\n",
       "         146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 158, 160,\n",
       "         161, 162, 163, 164, 166, 167, 168, 169, 172, 173, 174, 175, 176,\n",
       "         177, 178, 179, 180, 181, 182, 183, 184, 186, 187, 188, 189, 190,\n",
       "         191, 192, 193, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204,\n",
       "         206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218,\n",
       "         219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 230, 231, 232,\n",
       "         233, 234, 236, 237, 238, 239, 240, 242, 243, 244, 245, 246, 247,\n",
       "         248, 249, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 263,\n",
       "         264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 275, 276, 278,\n",
       "         279, 280, 281, 282, 284, 285, 286, 287, 288, 289, 290, 291, 292,\n",
       "         293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305,\n",
       "         306, 307, 308, 309, 311, 312, 313, 314, 315, 316, 317, 318, 320,\n",
       "         321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333,\n",
       "         334, 335, 336, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347,\n",
       "         348, 349, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 362,\n",
       "         363, 364, 365, 366, 367, 368, 369, 371, 372, 373, 374, 375, 376,\n",
       "         377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389,\n",
       "         390, 391, 392, 393, 395, 396, 397, 398, 399, 401, 402, 403, 405,\n",
       "         406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418,\n",
       "         419, 420, 421, 422, 423, 424, 425, 427, 428, 429, 430, 431, 432,\n",
       "         433, 434, 435, 436, 437, 439, 440, 441, 442, 443, 444, 445, 446,\n",
       "         447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459,\n",
       "         460, 461, 462, 463, 464, 465, 466, 467, 469, 471, 472, 474, 475,\n",
       "         477, 478, 479, 481, 482, 483, 485, 486, 487, 488, 489, 490, 491,\n",
       "         492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 503, 504, 505]),\n",
       "  array([ 12,  18,  38,  50,  51,  54,  68,  69,  77,  81,  89, 103, 113,\n",
       "         114, 131, 143, 157, 159, 165, 170, 171, 185, 194, 205, 229, 235,\n",
       "         241, 250, 261, 262, 274, 277, 283, 310, 319, 337, 350, 361, 370,\n",
       "         394, 400, 404, 426, 438, 468, 470, 473, 476, 480, 484, 502])),\n",
       " (array([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  12,  13,\n",
       "          14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,\n",
       "          27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,\n",
       "          40,  41,  42,  43,  44,  45,  46,  48,  49,  50,  51,  52,  53,\n",
       "          54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  65,  66,  67,\n",
       "          68,  69,  70,  72,  73,  74,  75,  77,  78,  79,  80,  81,  82,\n",
       "          83,  84,  85,  86,  88,  89,  90,  91,  92,  93,  94,  95,  96,\n",
       "          97,  98,  99, 100, 101, 102, 103, 104, 105, 106, 108, 109, 110,\n",
       "         111, 112, 113, 114, 115, 116, 118, 119, 120, 121, 122, 123, 124,\n",
       "         125, 126, 127, 128, 129, 130, 131, 132, 135, 136, 137, 138, 139,\n",
       "         140, 141, 142, 143, 144, 146, 149, 150, 151, 153, 154, 155, 156,\n",
       "         157, 158, 159, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170,\n",
       "         171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
       "         184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 198,\n",
       "         199, 200, 201, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213,\n",
       "         214, 215, 216, 217, 218, 219, 220, 222, 223, 225, 229, 230, 232,\n",
       "         233, 234, 235, 238, 239, 240, 241, 242, 243, 244, 245, 247, 248,\n",
       "         249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261,\n",
       "         262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 273, 274, 275,\n",
       "         276, 277, 278, 279, 280, 281, 283, 284, 285, 286, 287, 288, 289,\n",
       "         290, 291, 292, 294, 295, 297, 300, 301, 302, 303, 304, 305, 306,\n",
       "         307, 308, 309, 310, 311, 312, 315, 316, 317, 318, 319, 320, 322,\n",
       "         324, 325, 326, 328, 330, 331, 332, 333, 334, 335, 336, 337, 338,\n",
       "         339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351,\n",
       "         352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364,\n",
       "         365, 366, 367, 368, 370, 371, 372, 373, 374, 375, 376, 377, 378,\n",
       "         379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391,\n",
       "         392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404,\n",
       "         405, 406, 408, 409, 410, 411, 412, 413, 414, 415, 419, 420, 421,\n",
       "         422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 434, 436,\n",
       "         437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449,\n",
       "         450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 461, 462, 463,\n",
       "         464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476,\n",
       "         477, 478, 479, 480, 481, 482, 484, 485, 486, 487, 488, 489, 490,\n",
       "         491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 504,\n",
       "         505]),\n",
       "  array([ 11,  47,  64,  71,  76,  87, 107, 117, 133, 134, 145, 147, 148,\n",
       "         152, 160, 196, 197, 202, 203, 221, 224, 226, 227, 228, 231, 236,\n",
       "         237, 246, 272, 282, 293, 296, 298, 299, 313, 314, 321, 323, 327,\n",
       "         329, 369, 407, 416, 417, 418, 433, 435, 460, 483, 503])),\n",
       " (array([  0,   2,   3,   4,   5,   6,   8,  10,  11,  12,  13,  14,  17,\n",
       "          18,  19,  21,  24,  25,  26,  27,  28,  30,  31,  32,  33,  34,\n",
       "          35,  36,  37,  38,  39,  40,  41,  42,  43,  45,  46,  47,  48,\n",
       "          50,  51,  52,  53,  54,  55,  56,  57,  58,  59,  60,  61,  62,\n",
       "          63,  64,  65,  67,  68,  69,  71,  72,  74,  75,  76,  77,  78,\n",
       "          79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,\n",
       "          92,  93,  94,  95,  97,  98,  99, 100, 101, 102, 103, 104, 105,\n",
       "         106, 107, 108, 109, 110, 112, 113, 114, 115, 116, 117, 118, 120,\n",
       "         121, 122, 123, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134,\n",
       "         135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147,\n",
       "         148, 150, 151, 152, 153, 154, 155, 157, 159, 160, 161, 162, 163,\n",
       "         164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176,\n",
       "         177, 178, 179, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190,\n",
       "         191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203,\n",
       "         204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216,\n",
       "         217, 218, 219, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230,\n",
       "         231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243,\n",
       "         244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256,\n",
       "         257, 259, 260, 261, 262, 263, 264, 265, 266, 267, 269, 270, 271,\n",
       "         272, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285,\n",
       "         286, 287, 288, 289, 291, 293, 294, 295, 296, 297, 298, 299, 300,\n",
       "         302, 303, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315,\n",
       "         316, 317, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329,\n",
       "         331, 332, 333, 335, 336, 337, 339, 340, 341, 342, 343, 344, 345,\n",
       "         346, 347, 348, 349, 350, 351, 352, 353, 355, 356, 357, 358, 359,\n",
       "         361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373,\n",
       "         376, 377, 378, 380, 381, 382, 386, 387, 388, 389, 390, 391, 392,\n",
       "         393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405,\n",
       "         406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418,\n",
       "         419, 420, 421, 423, 424, 425, 426, 427, 429, 430, 431, 432, 433,\n",
       "         434, 435, 436, 437, 438, 439, 441, 442, 443, 444, 445, 446, 447,\n",
       "         448, 449, 450, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461,\n",
       "         462, 463, 464, 465, 466, 467, 468, 469, 470, 472, 473, 475, 476,\n",
       "         477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489,\n",
       "         490, 491, 492, 493, 495, 496, 497, 498, 499, 500, 501, 502, 503,\n",
       "         504]),\n",
       "  array([  1,   7,   9,  15,  16,  20,  22,  23,  29,  44,  49,  66,  70,\n",
       "          73,  96, 111, 119, 124, 149, 156, 158, 180, 220, 258, 268, 273,\n",
       "         290, 292, 301, 304, 318, 330, 334, 338, 354, 360, 374, 375, 379,\n",
       "         383, 384, 385, 422, 428, 440, 451, 471, 474, 494, 505])),\n",
       " (array([  0,   1,   2,   3,   6,   7,   8,   9,  10,  11,  12,  13,  15,\n",
       "          16,  18,  19,  20,  21,  22,  23,  24,  25,  26,  29,  30,  31,\n",
       "          33,  34,  36,  37,  38,  39,  40,  41,  42,  43,  44,  45,  46,\n",
       "          47,  49,  50,  51,  52,  54,  55,  56,  57,  58,  59,  60,  62,\n",
       "          63,  64,  65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,\n",
       "          76,  77,  78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,\n",
       "          89,  90,  91,  92,  94,  96,  97,  98,  99, 100, 101, 102, 103,\n",
       "         104, 106, 107, 108, 109, 110, 111, 112, 113, 114, 116, 117, 118,\n",
       "         119, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134,\n",
       "         135, 138, 139, 140, 141, 143, 145, 146, 147, 148, 149, 150, 151,\n",
       "         152, 153, 155, 156, 157, 158, 159, 160, 161, 162, 164, 165, 166,\n",
       "         167, 168, 169, 170, 171, 173, 174, 175, 176, 177, 179, 180, 181,\n",
       "         182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194,\n",
       "         195, 196, 197, 199, 200, 201, 202, 203, 204, 205, 207, 208, 210,\n",
       "         211, 212, 213, 214, 215, 216, 218, 219, 220, 221, 222, 224, 225,\n",
       "         226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238,\n",
       "         240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252,\n",
       "         254, 255, 256, 257, 258, 259, 261, 262, 263, 266, 267, 268, 269,\n",
       "         270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282,\n",
       "         283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295,\n",
       "         296, 297, 298, 299, 300, 301, 302, 303, 304, 307, 309, 310, 311,\n",
       "         312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324,\n",
       "         325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337,\n",
       "         338, 339, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351,\n",
       "         352, 353, 354, 355, 357, 358, 359, 360, 361, 362, 363, 365, 366,\n",
       "         367, 368, 369, 370, 371, 372, 373, 374, 375, 377, 378, 379, 380,\n",
       "         381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 392, 393, 394,\n",
       "         395, 396, 397, 398, 400, 401, 402, 403, 404, 405, 406, 407, 408,\n",
       "         409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 421, 422,\n",
       "         423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435,\n",
       "         436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448,\n",
       "         450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462,\n",
       "         463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475,\n",
       "         476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488,\n",
       "         489, 490, 491, 493, 494, 496, 497, 499, 500, 501, 502, 503, 504,\n",
       "         505]),\n",
       "  array([  4,   5,  14,  17,  27,  28,  32,  35,  48,  53,  61,  93,  95,\n",
       "         105, 115, 120, 121, 122, 136, 137, 142, 144, 154, 163, 172, 178,\n",
       "         198, 206, 209, 217, 223, 239, 253, 260, 264, 265, 305, 306, 308,\n",
       "         340, 356, 364, 376, 391, 399, 420, 449, 492, 495, 498])),\n",
       " (array([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,\n",
       "          13,  14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,\n",
       "          26,  27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,\n",
       "          39,  40,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,\n",
       "          53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,  65,\n",
       "          66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,  78,\n",
       "          79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  91,  92,\n",
       "          93,  94,  95,  96,  97,  98,  99, 101, 102, 103, 104, 105, 106,\n",
       "         107, 108, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121,\n",
       "         122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 133, 134, 135,\n",
       "         136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148,\n",
       "         149, 150, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 163,\n",
       "         164, 165, 166, 167, 169, 170, 171, 172, 173, 174, 175, 176, 178,\n",
       "         179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191,\n",
       "         192, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205,\n",
       "         206, 207, 208, 209, 210, 211, 214, 215, 216, 217, 218, 220, 221,\n",
       "         222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 234, 235,\n",
       "         236, 237, 238, 239, 240, 241, 242, 243, 244, 246, 247, 248, 249,\n",
       "         250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262,\n",
       "         264, 265, 266, 267, 268, 270, 271, 272, 273, 274, 275, 276, 277,\n",
       "         278, 279, 281, 282, 283, 285, 287, 288, 289, 290, 291, 292, 293,\n",
       "         294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306,\n",
       "         307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319,\n",
       "         320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332,\n",
       "         333, 334, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346,\n",
       "         347, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360,\n",
       "         361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373,\n",
       "         374, 375, 376, 377, 378, 379, 380, 381, 383, 384, 385, 386, 387,\n",
       "         388, 389, 391, 393, 394, 395, 396, 399, 400, 401, 402, 403, 404,\n",
       "         405, 406, 407, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419,\n",
       "         420, 421, 422, 423, 424, 426, 427, 428, 429, 430, 431, 433, 435,\n",
       "         436, 438, 439, 440, 441, 443, 444, 446, 447, 448, 449, 450, 451,\n",
       "         452, 453, 455, 456, 457, 459, 460, 462, 463, 464, 465, 466, 467,\n",
       "         468, 470, 471, 473, 474, 476, 477, 478, 479, 480, 481, 483, 484,\n",
       "         486, 490, 491, 492, 494, 495, 497, 498, 499, 501, 502, 503, 504,\n",
       "         505]),\n",
       "  array([ 41,  90, 100, 109, 110, 132, 151, 162, 168, 177, 193, 212, 213,\n",
       "         219, 233, 245, 263, 269, 280, 284, 286, 335, 348, 382, 390, 392,\n",
       "         397, 398, 408, 409, 425, 432, 434, 437, 442, 445, 454, 458, 461,\n",
       "         469, 472, 475, 482, 485, 487, 488, 489, 493, 496, 500]))]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(cv.split(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(cv.split(X)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 2.42\n"
     ]
    }
   ],
   "source": [
    "rand_reg = RandomForestRegressor(n_estimators = 10, random_state = 42)\n",
    "for train_fold, valid_fold in cv.split(X):\n",
    "    X_train = X.loc[train_fold] # Extract train data with cv indices\n",
    "    X_valid = X.loc[valid_fold] # Extract valid data with cv indices\n",
    "    \n",
    "    y_train = y.loc[train_fold]\n",
    "    y_valid = y.loc[valid_fold]\n",
    "    \n",
    "    model = rand_reg.fit(X = X_train, y = y_train)\n",
    "    model_pred = model.predict(X = X_valid)\n",
    "    errors = abs(model_pred - y_valid)\n",
    "# Print out the mean absolute error\n",
    "print('Mean Absolute Error:', round(np.mean(errors), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([32.13, 21.68, 25.78, 19.64, 19.62, 19.42, 20.48, 45.65, 21.42,\n",
       "       23.72])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the first 10 true and predicted responses\n",
    "model_pred[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([26.6, 22.6, 27.5, 19.4, 21.7, 23. , 19.6, 50. , 23.8, 24.6])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_valid[0:10].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataset into Training set and Test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(n_estimators=10, random_state=42)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand_reg = RandomForestRegressor(n_estimators = 10, random_state = 42)\n",
    "rand_reg.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = rand_reg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([23.49, 30.14, 17.86, 23.32, 16.29, 21.8 , 20.85, 16.54, 20.75,\n",
       "       19.96, 19.04, 19.59,  8.38, 21.42, 18.51, 22.08, 18.66,  8.82,\n",
       "       47.08, 15.84, 24.17, 25.98, 14.42, 23.7 , 13.54, 14.17, 21.48,\n",
       "       14.32, 18.82, 20.99, 19.56, 23.62, 32.77, 20.03, 14.33, 14.87,\n",
       "       32.92, 18.78, 21.6 , 24.04, 19.77, 29.34, 44.96, 19.69, 23.56,\n",
       "       13.62, 15.  , 24.67, 18.75, 28.13, 19.45, 33.68, 16.16, 25.18,\n",
       "       43.58, 22.38, 14.66, 29.71, 22.42, 20.67, 25.93, 33.9 , 26.  ,\n",
       "       18.12, 25.38, 15.59, 12.92, 23.7 , 28.22, 14.97, 21.12, 27.03,\n",
       "       10.94, 19.94, 22.38,  7.65, 19.94, 45.05, 11.23, 13.45, 21.1 ,\n",
       "       14.51, 17.54,  9.97, 20.02, 26.99, 14.81, 23.58, 23.29, 17.49,\n",
       "       21.03,  7.32, 19.12, 18.97, 25.73, 19.87, 44.39, 14.5 , 12.57,\n",
       "       14.11, 20.25, 23.85])"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 2.08\n"
     ]
    }
   ],
   "source": [
    "# Calculate the absolute errors\n",
    "errors = abs(y_pred - y_test)\n",
    "# Print out the mean absolute error\n",
    "print('Mean Absolute Error:', round(np.mean(errors), 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Observation : Applying 10 fold cross validation on datapoints and fitting those in random forest regressor, Mean absolute error value is 2.42 as opposed to Mean absolute error value of 2.08 while applying train test split in random forest regressor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test =train_test_split(X,y,random_state=2103)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from scipy.special import comb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "#from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "#from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn import tree \n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "#from sklearn.metrics import accuracy_score,confusion_matrix,roc_curve,roc_auc_score\n",
    "#from sklearn.externals.six  \n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "from IPython.display import Image  \n",
    "from sklearn.tree import export_graphviz\n",
    "#import pydotplus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor()"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#let's first visualize the tree on the data without doing any pre processing\n",
    "clf = DecisionTreeRegressor()\n",
    "clf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### We have not done scaling bcoz its a Tree based model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8136476443940035"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_reg= RandomForestRegressor(random_state=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(random_state=6)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand_reg.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8900647368569015"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand_reg.score(X_test,y_test)##returns R Squared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### We see that the accuracy has hugely improved using Random Forest inplace of Dtree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Random forest hyperparameters are a combination of best hyperparameters of both decision tree and Bagging classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### GridSearchCV is a method used to tune our hyperparameters. We can pass different values of hyperparameters as parameters\n",
    "#### for grid search. It does a exhaustive generation of combination of different parameters passed.\n",
    "#Using cross validation score, Grid Search returns the combination of hyperparameters for which the model is performing the best."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # we are tuning three hyperparameters right now, we are passing the different values for both parameters\n",
    "# grid_param = {\n",
    "#     \"n_estimators\" : [90,100,115,130],\n",
    "#     'criterion': ['mse', 'entropy'],\n",
    "#     'max_depth' : range(2,20,1),\n",
    "#     'min_samples_leaf' : range(1,10,1),\n",
    "#     'min_samples_split': range(2,10,1),\n",
    "#     'max_features' : ['auto','log2']\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#grid_search = GridSearchCV(estimator=rand_reg,param_grid=grid_param,cv=5,n_jobs =-1,verbose = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "#(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "#let's see the best parameters as per our grid search\n",
    "#grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # let's save the model\n",
    "\n",
    "# import pickle\n",
    "\n",
    "# with open('D:\\ineuron_materials_ipynb\\iNeuron\\EnsembleLearning_And_RandomForest'+ '/modelForPrediction.sav', 'wb') as f:\n",
    "#     pickle.dump(rand_reg,f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rand_reg = RandomForestRegressor(criterion= 'gini',\n",
    "#  max_features = 'auto',\n",
    "#  min_samples_leaf = 1,\n",
    "#  min_samples_split= 2,\n",
    "#  n_estimators = 90,random_state=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rand_reg(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "####This error occurs when we miss giving .fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rand_reg.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
